/* -*- mode: C; tab-width: 2; indent-tabs-mode: nil; -*- */

/*
 * This code has been contributed by the DARPA HPCS program.  Contact
 * David Koester <dkoester@mitre.org> or Bob Lucas <rflucas@isi.edu>
 * if you have questions.
 *
 *
 * GUPS (Giga UPdates per Second) is a measurement that profiles the memory
 * architecture of a system and is a measure of performance similar to MFLOPS.
 * The HPCS HPCchallenge RandomAccess benchmark is intended to exercise the
 * GUPS capability of a system, much like the LINPACK benchmark is intended to
 * exercise the MFLOPS capability of a computer.  In each case, we would
 * expect these benchmarks to achieve close to the "peak" capability of the
 * memory system. The extent of the similarities between RandomAccess and
 * LINPACK are limited to both benchmarks attempting to calculate a peak system
 * capability.
 *
 * GUPS is calculated by identifying the number of memory locations that can be
 * randomly updated in one second, divided by 1 billion (1e9). The term "randomly"
 * means that there is little relationship between one address to be updated and
 * the next, except that they occur in the space of one half the total system
 * memory.  An update is a read-modify-write operation on a table of 64-bit words.
 * An address is generated, the value at that address read from memory, modified
 * by an integer operation (add, and, or, xor) with a literal value, and that
 * new value is written back to memory.
 *
 * We are interested in knowing the GUPS performance of both entire systems and
 * system subcomponents --- e.g., the GUPS rating of a distributed memory
 * multiprocessor the GUPS rating of an SMP node, and the GUPS rating of a
 * single processor.  While there is typically a scaling of FLOPS with processor
 * count, a similar phenomenon may not always occur for GUPS.
 *
 * Select the memory size to be the power of two such that 2^n <= 1/2 of the
 * total memory.  Each CPU operates on its own address stream, and the single
 * table may be distributed among nodes. The distribution of memory to nodes
 * is left to the implementer.  A uniform data distribution may help balance
 * the workload, while non-uniform data distributions may simplify the
 * calculations that identify processor location by eliminating the requirement
 * for integer divides. A small (less than 1%) percentage of missed updates
 * are permitted.
 *
 * When implementing a benchmark that measures GUPS on a distributed memory
 * multiprocessor system, it may be required to define constraints as to how
 * far in the random address stream each node is permitted to "look ahead".
 * Likewise, it may be required to define a constraint as to the number of
 * update messages that can be stored before processing to permit multi-level
 * parallelism for those systems that support such a paradigm.  The limits on
 * "look ahead" and "stored updates" are being implemented to assure that the
 * benchmark meets the intent to profile memory architecture and not induce
 * significant artificial data locality. For the purpose of measuring GUPS,
 * we will stipulate that each thread is permitted to look ahead no more than
 * 1024 random address stream samples with the same number of update messages
 * stored before processing.
 *
 * The supplied MPI-1 code generates the input stream {A} on all processors
 * and the global table has been distributed as uniformly as possible to
 * balance the workload and minimize any Amdahl fraction.  This code does not
 * exploit "look-ahead".  Addresses are sent to the appropriate processor
 * where the table entry resides as soon as each address is calculated.
 * Updates are performed as addresses are received.  Each message is limited
 * to a single 64 bit long integer containing element ai from {A}.
 * Local offsets for T[ ] are extracted by the destination processor.
 *
 * If the number of processors is equal to a power of two, then the global
 * table can be distributed equally over the processors.  In addition, the
 * processor number can be determined from that portion of the input stream
 * that identifies the address into the global table by masking off log2(p)
 * bits in the address.
 *
 * If the number of processors is not equal to a power of two, then the global
 * table cannot be equally distributed between processors.  In the MPI-1
 * implementation provided, there has been an attempt to minimize the differences
 * in workloads and the largest difference in elements of T[ ] is one.  The
 * number of values in the input stream generated by each processor will be
 * related to the number of global table entries on each processor.
 *
 * The MPI-1 version of RandomAccess treats the potential instance where the
 * number of processors is a power of two as a special case, because of the
 * significant simplifications possible because processor location and local
 * offset can be determined by applying masks to the input stream values.
 * The non power of two case uses an integer division to determine the processor
 * location.  The integer division will be more costly in terms of machine
 * cycles to perform than the bit masking operations
 *
 * For additional information on the GUPS metric, the HPCchallenge RandomAccess
 * Benchmark,and the rules to run RandomAccess or modify it to optimize
 * performance -- see http://icl.cs.utk.edu/hpcc/
 *
 */

 ////////////////////////////////////////////////////////////////////////////////////////////////////
 // file:	altis\src\cuda\level2\dwt2d\gups\gups.cu
 //
 // summary:	Random access class
 // 
 // origin: HPCchallenge RandomAccess Benchmark(http://icl.cs.utk.edu/hpcc/)
 ////////////////////////////////////////////////////////////////////////////////////////////////////

#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>


#include <cstdlib>
#include <cuda.h>
#include <iostream>

#include "OptionParser.h"
#include "ResultDatabase.h"
#include "cudacommon.h"

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	A macro that defines default logn for memory size. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
////////////////////////////////////////////////////////////////////////////////////////////////////

#define DEFAULT_LOGN 20

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	A macro that defines Polygon. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
////////////////////////////////////////////////////////////////////////////////////////////////////

#define POLY 0x0000000000000007ULL

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	A macro that defines default GPU. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
////////////////////////////////////////////////////////////////////////////////////////////////////

#define DEFAULT_GPU 0

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	A benchtype. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
////////////////////////////////////////////////////////////////////////////////////////////////////

union benchtype {
  /// <summary>	The 64. </summary>
  uint64_t u64;
  /// <summary>	The 32. </summary>
  uint2 u32;
};

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Gets the 2[64]. </summary>
///
/// <value>	The c m 2[64]. </value>
////////////////////////////////////////////////////////////////////////////////////////////////////

static __constant__ uint64_t c_m2[64];

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Gets the error[ 1]. </summary>
///
/// <value>	The d error[ 1]. </value>
////////////////////////////////////////////////////////////////////////////////////////////////////

static __device__ uint32_t d_error[1];

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Initializes this.  </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
///
/// <param name="n">	A size_t to process. </param>
/// <param name="t">	[in,out] If non-null, a benchtype to process. </param>
////////////////////////////////////////////////////////////////////////////////////////////////////

static __global__ void
d_init(size_t n, benchtype *t)
{
  for (ptrdiff_t i = blockIdx.x * blockDim.x + threadIdx.x; i < n;
       i += gridDim.x * blockDim.x) {
    t[i].u64 = i;
  }
}

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Starts the given n. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
///
/// <param name="n">	A size_t to process. </param>
///
/// <returns>	An uint64_t. </returns>
////////////////////////////////////////////////////////////////////////////////////////////////////

static __device__ uint64_t
d_starts(size_t n)
{
  if (n == 0) {
    return 1;
  }

  int i = 63 - __clzll(n);

  uint64_t ran = 2;
  while (i > 0) {
    uint64_t temp = 0;
    for (int j = 0; j < 64; j++) {
      if ((ran >> j) & 1) {
        temp ^= c_m2[j];
      }
    }
    ran = temp;
    i -= 1;
    if ((n >> i) & 1) {
      ran = (ran << 1) ^ ((int64_t) ran < 0 ? POLY : 0);
    }
  }

  return ran;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Values that represent atomictype ts. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
////////////////////////////////////////////////////////////////////////////////////////////////////

enum atomictype_t {
  ATOMICTYPE_CAS,
  ATOMICTYPE_XOR,
};

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Benches. </summary>
///
/// <typeparam name="ATOMICTYPE">	Type of the atomictype. </typeparam>
/// <param name="n">	A size_t to process. </param>
/// <param name="t">	[in,out] If non-null, a benchtype to process. </param>
////////////////////////////////////////////////////////////////////////////////////////////////////

template<atomictype_t ATOMICTYPE>
__global__ void
d_bench(size_t n, benchtype *t)
{
  size_t num_threads = gridDim.x * blockDim.x;
  size_t thread_num = blockIdx.x * blockDim.x + threadIdx.x;
  size_t start = thread_num * 4 * n / num_threads;
  size_t end = (thread_num + 1) * 4 * n / num_threads;
  benchtype ran;
  ran.u64 = d_starts(start);
  for (ptrdiff_t i = start; i < end; ++i) {
    ran.u64 = (ran.u64 << 1) ^ ((int64_t) ran.u64 < 0 ? POLY : 0);
    switch (ATOMICTYPE) {
    case ATOMICTYPE_CAS:
      unsigned long long int *address, old, assumed;
      address = (unsigned long long int *)&t[ran.u64 & (n - 1)].u64;
      old = *address;
      do {
        assumed = old;
        old = atomicCAS(address, assumed, assumed ^ ran.u64);
      } while  (assumed != old);
      break;
    case ATOMICTYPE_XOR:
      atomicXor(&t[ran.u64 & (n - 1)].u32.x, ran.u32.x);
      atomicXor(&t[ran.u64 & (n - 1)].u32.y, ran.u32.y);
      break;
    }
  }
}

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Checks. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
///
/// <param name="n">	A size_t to process. </param>
/// <param name="t">	[in,out] If non-null, a benchtype to process. </param>
////////////////////////////////////////////////////////////////////////////////////////////////////

static __global__ void
d_check(size_t n, benchtype *t)
{
  for (ptrdiff_t i = blockIdx.x * blockDim.x + threadIdx.x; i < n;
       i += gridDim.x * blockDim.x) {
    if (t[i].u64 != i) {
      atomicAdd(d_error, 1);
    }
  }
}

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Starts this.  </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
////////////////////////////////////////////////////////////////////////////////////////////////////

static void
starts()
{
  uint64_t m2[64];
  uint64_t temp = 1;
  for (ptrdiff_t i = 0; i < 64; i++) {
    m2[i] = temp;
    temp = (temp << 1) ^ ((int64_t) temp < 0 ? POLY : 0);
    temp = (temp << 1) ^ ((int64_t) temp < 0 ? POLY : 0);
  }
  checkCudaErrors(cudaMemcpyToSymbol(c_m2, m2, sizeof(m2)));
}

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Adds a benchmark specifier options. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
///
/// <param name="op">	[in,out] The operation. </param>
////////////////////////////////////////////////////////////////////////////////////////////////////

void addBenchmarkSpecOptions(OptionParser &op) {
   // TODO, maybe add benchmark specs 
  op.addOption("shifts", OPT_INT, "20", "specify bit shift for the number of elements in update table", '\0');
}

//int main(int argc, char *argv[])
//{

////////////////////////////////////////////////////////////////////////////////////////////////////
/// <summary>	Executes the benchmark operation. </summary>
///
/// <remarks>	Edward Hu (bodunhu@utexas.edu), 5/20/2020. </remarks>
///
/// <param name="DB">	[in,out] The database. </param>
/// <param name="op">	[in,out] The operation. </param>
////////////////////////////////////////////////////////////////////////////////////////////////////

void RunBenchmark(ResultDatabase &DB, OptionParser &op) {
  std::cout << "Running GUPS" << std::endl;
  size_t n = 0;
  const int passes = op.getOptionInt("passes");
  const bool uvm = op.getOptionBool("uvm");
  int device = 0;
  checkCudaErrors(cudaGetDevice(&device));

  // Specify table size
  int problemSizes[5] = {20, 22, 24, 26, 32}; // size 5 might be extremely long!
  int toShifts = problemSizes[op.getOptionInt("size") - 1];

  int logn = op.getOptionInt("shifts");
  // TODO: watch out size
  if (logn > 0 && logn != 20) {
    n = (size_t) 1 << logn;
  } else {
    n = (size_t) 1 << toShifts;
  }

  std::cout << "Total table size = " << n << " (" << n*sizeof(uint64_t) << " bytes.)" << std::endl;

  starts();

  int ndev;
  checkCudaErrors(cudaGetDeviceCount(&ndev));
  int dev = op.getOptionInt("device");

  cudaDeviceProp prop;
  checkCudaErrors(cudaGetDeviceProperties(&prop, device));
  checkCudaErrors(cudaSetDevice(dev));
  printf("Using GPU %d of %d GPUs.\n", dev, ndev);
  printf("Warp size = %d.\n", prop.warpSize);
  printf("Multi-processor count = %d.\n", prop.multiProcessorCount);
  printf("Max threads per multi-processor = %d.\n",
         prop.maxThreadsPerMultiProcessor);

  benchtype *d_t = NULL;
  if (uvm) {
    checkCudaErrors(cudaMallocManaged((void **)&d_t, n * sizeof(benchtype)));
  } else {
    checkCudaErrors(cudaMalloc((void **)&d_t, n * sizeof(benchtype)));
  }

  // max warp size
  dim3 grid(prop.multiProcessorCount *
            (prop.maxThreadsPerMultiProcessor / prop.warpSize));
  // # as if scheduling warps instead of blocks
  dim3 thread(prop.warpSize);
  cudaEvent_t begin, end;
  checkCudaErrors(cudaEventCreate(&begin));
  checkCudaErrors(cudaEventCreate(&end));
  void *p_error;
  checkCudaErrors(cudaGetSymbolAddress(&p_error, d_error));

  string atts = "ATOMICTYPE_CAS";
  for (int i = 0; i < passes; i++) {
    d_init<<<grid, thread>>>(n, d_t);
    checkCudaErrors(cudaEventRecord(begin));
    d_bench<ATOMICTYPE_CAS><<<grid, thread>>>(n, d_t);
    checkCudaErrors(cudaEventRecord(end));
    checkCudaErrors(cudaEventSynchronize(end));

    float ms;
    checkCudaErrors(cudaEventElapsedTime(&ms, begin, end));

    double time = ms * 1.0e-3;
    DB.AddResult("Elapsed time", atts, "seconds", time);
    double gups = 4 * n / (double) ms * 1.0e-6;
    DB.AddResult("Giga Updates per second", atts, "GUP/s", gups);

    cudaMemset(d_error, 0, sizeof(uint32_t));
    d_check<<<grid, thread>>>(n, d_t);
    uint32_t h_error;
    checkCudaErrors(cudaMemcpy(&h_error, p_error, sizeof(uint32_t), cudaMemcpyDeviceToHost));
    if (op.getOptionBool("verbose")) {
      printf("Verification (ATOMICTYPE_CAS): Found %u errors.\n", h_error);
    }
  }

  atts = "ATOMICTYPE_XOR";
  for (int i = 0; i < passes; i++) {
    d_init<<<grid, thread>>>(n, d_t);
    checkCudaErrors(cudaEventRecord(begin));
    d_bench<ATOMICTYPE_XOR><<<grid, thread>>>(n, d_t);
    checkCudaErrors(cudaEventRecord(end));
    checkCudaErrors(cudaEventSynchronize(end));

    float ms;
    checkCudaErrors(cudaEventElapsedTime(&ms, begin, end));

    double time = ms * 1.0e-3;
    DB.AddResult("Elapsed time", atts, "seconds", time);
    double gups = 4 * n / (double) ms * 1.0e-6;
    DB.AddResult("Giga Updates per second", atts, "GUP/s", gups);
    // d_bench<ATOMICTYPE_XOR><<<grid, thread>>>(n, d_t);
    // void *p_error;
    // checkCudaErrors(cudaGetSymbolAddress(&p_error, d_error));
    cudaMemset(d_error, 0, sizeof(uint32_t));
    d_check<<<grid, thread>>>(n, d_t);
    uint32_t h_error;
    checkCudaErrors(cudaMemcpy(&h_error, p_error, sizeof(uint32_t), cudaMemcpyDeviceToHost));
    if (op.getOptionBool("verbose")) {
      printf("Verification (ATOMICTYPE_XOR): Found %u errors.\n", h_error);
    }
  }

  checkCudaErrors(cudaEventDestroy(end));
  checkCudaErrors(cudaEventDestroy(begin));
  checkCudaErrors(cudaFree(d_t));
}
